{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR 1: PROJ: proj_create_from_database: Open of /net/nfs/tools/u20/Python/miniconda3_py311_23.11.0-2/envs/pangeo-meso-2024.01.22/share/proj failed\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 108\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;66;03m#Rainf_new = da.where(mask == 1, Rainf, Fill_value)\u001b[39;00m\n\u001b[1;32m    107\u001b[0m     Snowf \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mlen\u001b[39m(PSurf\u001b[38;5;241m.\u001b[39mtime), \u001b[38;5;28mlen\u001b[39m(Prec\u001b[38;5;241m.\u001b[39mrlat), \u001b[38;5;28mlen\u001b[39m(Prec\u001b[38;5;241m.\u001b[39mrlon)))\u001b[38;5;66;03m#, chunks=(200, len(rlat), len(rlon)))  \u001b[39;00m\n\u001b[0;32m--> 108\u001b[0m     Snowf\u001b[38;5;241m=\u001b[39m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTair\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m273.15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPrec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m#*mask\u001b[39;00m\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;66;03m#Snowf_new = da.where(mask == 1, Snowf, Fill_value)\u001b[39;00m\n\u001b[1;32m    110\u001b[0m  \n\u001b[1;32m    111\u001b[0m \n\u001b[1;32m    112\u001b[0m \u001b[38;5;66;03m############## OUTPUT PATH #########################################\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     rootpath_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/modfs/project/input4CORDEX/output/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;66;03m#sostituire /scratchx/lrapella con /bdd\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import netCDF4 as nc\n",
    "import cartopy.crs as ccrs\n",
    "from datetime import date, timedelta, datetime\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import dask.array as da \n",
    "import os\n",
    "import cftime\n",
    "\n",
    "############ INPUT PATH ##############\n",
    "\n",
    "rootpath_in = '/bdd/CORDEX/output/'\n",
    "CORDEX_domain = 'EUR-11'\n",
    "GCM = 'NCC-NorESM1-M'\n",
    "scenario = 'rcp45'\n",
    "RCM = 'DMI-HIRHAM5'\n",
    "em = 'r1i1p1' #ensemble_member\n",
    "ver='v3' #version\n",
    "freq='3hr' #frequency\n",
    "ver_2='latest'\n",
    "#version_3=..\n",
    "#version_4=..\n",
    "HH_1s='0130' #start hour averaged variables (see README.txt)\n",
    "HH_2s='0000' #start hour instantaneous variables \n",
    "HH_1e='2230' #end hour averaged variables \n",
    "HH_2e='2100' #end hour instantaneous variables\n",
    "\n",
    "forcing_in = rootpath_in+CORDEX_domain+'/DMI/'+GCM+'/'+scenario+'/'+em+'/'+RCM+'/'+ver+'/'+freq \n",
    "\n",
    "############################# TIME RANGE DEFINITION ###########\n",
    "\n",
    "first_year = 2006\n",
    "last_year = 2100\n",
    "\n",
    "years=np.arange(first_year, last_year+1, 1) #right value excluded\n",
    "\n",
    "################################# MASK CALL ######\n",
    "\n",
    "mask_ocean=xr.open_dataset('/modfs/project/input4CORDEX/output/EUR-11/grid_rotated.nc') #put this file in the shared directory, #modificare il path in modo interattivo\n",
    "mask=mask_ocean.LANDMASK.data\n",
    "\n",
    "#################### VARIABLES CALL ##################\n",
    "\n",
    "for y in years:\n",
    "    rsds_open= forcing_in+'/rsds/'+ver_2+'/rsds_'+CORDEX_domain+'_'+GCM+'_'+scenario+'_'+em+'_'+RCM+'_'+ver+'_'+freq+'_'+str(y)+'0101'+HH_1s+'-'+str(y)+'1231'+HH_1e+'.nc'\n",
    "    rlds_open= forcing_in+'/rlds/'+ver_2+'/rlds_'+CORDEX_domain+'_'+GCM+'_'+scenario+'_'+em+'_'+RCM+'_'+ver+'_'+freq+'_'+str(y)+'0101'+HH_1s+'-'+str(y)+'1231'+HH_1e+'.nc'\n",
    "    sfcWind_open= forcing_in+'/sfcWind/'+ver_2+'/sfcWind_'+CORDEX_domain+'_'+GCM+'_'+scenario+'_'+em+'_'+RCM+'_'+ver+'_'+freq+'_'+str(y)+'0101'+HH_2s+'-'+str(y)+'1231'+HH_2e+'.nc'\n",
    "    tas_open= forcing_in+'/tas/'+ver_2+'/tas_'+CORDEX_domain+'_'+GCM+'_'+scenario+'_'+em+'_'+RCM+'_'+ver+'_'+freq+'_'+str(y)+'0101'+HH_2s+'-'+str(y)+'1231'+HH_2e+'.nc'\n",
    "    huss_open= forcing_in+'/huss/'+ver_2+'/huss_'+CORDEX_domain+'_'+GCM+'_'+scenario+'_'+em+'_'+RCM+'_'+ver+'_'+freq+'_'+str(y)+'0101'+HH_2s+'-'+str(y)+'1231'+HH_2e+'.nc'\n",
    "    pr_open= forcing_in+'/pr/'+ver_2+'/pr_'+CORDEX_domain+'_'+GCM+'_'+scenario+'_'+em+'_'+RCM+'_'+ver+'_'+freq+'_'+str(y)+'0101'+HH_1s+'-'+str(y)+'1231'+HH_1e+'.nc'\n",
    "    ps_open= forcing_in+'/ps/'+ver_2+'/ps_'+CORDEX_domain+'_'+GCM+'_'+scenario+'_'+em+'_'+RCM+'_'+ver+'_'+freq+'_'+str(y)+'0101'+HH_2s+'-'+str(y)+'1231'+HH_2e+'.nc'\n",
    "    \n",
    "    shortwave_radiation=xr.open_mfdataset(rsds_open, combine='by_coords', parallel=True,  chunks={'time': 200}) #chuncks, to optimize memory use\n",
    "    longwave_radiation=xr.open_mfdataset(rlds_open, combine='by_coords', parallel=True,  chunks={'time': 200})\n",
    "    surface_wind=xr.open_mfdataset(sfcWind_open, combine='by_coords', parallel=True,  chunks={'time': 200})\n",
    "    air_temperature=xr.open_mfdataset(tas_open, combine='by_coords', parallel=True,  chunks={'time': 200})\n",
    "    specific_humidity=xr.open_mfdataset(huss_open, combine='by_coords', parallel=True,  chunks={'time': 200})\n",
    "    total_precipitation=xr.open_mfdataset(pr_open, combine='by_coords', parallel=True,  chunks={'time': 200})\n",
    "    surface_pressure=xr.open_mfdataset(ps_open, combine='by_coords', parallel=True,  chunks={'time': 200})\n",
    "    \n",
    "    times= shortwave_radiation.time\n",
    "    rlat = shortwave_radiation.rlat\n",
    "    rlon = shortwave_radiation.rlon\n",
    "    lat = shortwave_radiation.lat\n",
    "    lon = shortwave_radiation.lon\n",
    "\n",
    "    Fill_value = 9.96921e+36\n",
    "    SWdown=shortwave_radiation.rename({'rsds': 'SWdown'}).SWdown*mask\n",
    "    #SWdown_new = da.where(mask == 1, SWdown, Fill_value) #mask filter to keep only land values\n",
    "    \n",
    "    LWdown=longwave_radiation.rename({'rlds': 'LWdown'}).LWdown*mask\n",
    "    #LWdown_new = da.where(mask == 1, LWdown, Fill_value)\n",
    "    \n",
    "    Wind=surface_wind.rename({'sfcWind': 'Wind'}).Wind*mask\n",
    "    #Wind_new = da.where(mask == 1, Wind, Fill_value)\n",
    "    \n",
    "    Tair=air_temperature.rename({'tas': 'Tair'}).Tair*mask\n",
    "    #Tair_new = da.where(mask == 1, Tair, Fill_value)\n",
    "    \n",
    "    Qair=specific_humidity.rename({'huss': 'Qair'}).Qair*mask\n",
    "    #Qair_new = da.where(mask == 1, Qair, Fill_value)\n",
    "\n",
    "    PSurf = surface_pressure.rename({'ps': 'PSurf'}).PSurf*mask\n",
    "    #Psurf_new = da.where(mask == 1, Psurf, Fill_value)\n",
    "\n",
    "    Prec = total_precipitation.rename({'pr': 'Prec'}).Prec*mask\n",
    " \n",
    "    #PSurf = PSurf.isel(rlat=slice(100, 180)).isel(rlon=slice(100, 255))\n",
    "    #Tair = Tair.isel(rlat=slice(100, 180)).isel(rlon=slice(100, 255))\n",
    "    #SWdown = SWdown.isel(rlat=slice(100, 180)).isel(rlon=slice(100, 255))\n",
    "    #LWdown = LWdown.isel(rlat=slice(100, 180)).isel(rlon=slice(100, 255))\n",
    "    #Qair = Qair.isel(rlat=slice(100, 180)).isel(rlon=slice(100, 255))\n",
    "    #Wind = Wind.isel(rlat=slice(100, 180)).isel(rlon=slice(100, 255))\n",
    "    #Prec = Prec.isel(rlat=slice(100, 180)).isel(rlon=slice(100, 255))\n",
    "    \n",
    "    tstep_data = np.arange(0, len(PSurf.time))\n",
    "    first_value = 3600 + 1800 # the original files start at 01:30\n",
    "    time_step = 3*3600 # 3hourly data\n",
    "    times_data= first_value +((tstep_data) * time_step)\n",
    "                     \n",
    "    Rainf = np.zeros((len(PSurf.time), len(Prec.rlat), len(Prec.rlon)))#, chunks=(200, len(rlat), len(rlon)))\n",
    "    Rainf=np.where(Tair > 273.15, Prec, 0)#*mask\n",
    "    #Rainf_new = da.where(mask == 1, Rainf, Fill_value)\n",
    "\n",
    "    Snowf = np.zeros((len(PSurf.time), len(Prec.rlat), len(Prec.rlon)))#, chunks=(200, len(rlat), len(rlon)))  \n",
    "    Snowf=np.where(Tair <= 273.15, Prec, 0)#*mask\n",
    "    #Snowf_new = da.where(mask == 1, Snowf, Fill_value)\n",
    " \n",
    "\n",
    "############## OUTPUT PATH #########################################\n",
    "    rootpath_out = '/modfs/project/input4CORDEX/output/' #sostituire /scratchx/lrapella con /bdd\n",
    "    #rootpath_out = '/bdd/E4C/E4C_AgriPV/Forcing4CORDEX/output/' #sostituire /scratchx/lrapella con /bdd\n",
    "\n",
    "    forcing_out = rootpath_out+CORDEX_domain+'/DMI/'+GCM+'/'+scenario+'/'+em+'/'+RCM+'/'+ver+'/'+freq+'/forcing_'+CORDEX_domain+'_'+GCM+'_'+scenario+'_'+em+'_'+RCM+'_'+ver+'_'+freq+'_'+str(y)+'.nc'\n",
    "\n",
    "    if not os.path.isdir(os.path.dirname(forcing_out)):\n",
    "        os.makedirs(os.path.dirname(forcing_out))\n",
    "\n",
    "########### CREATION OUTPUT DATASET ################################### \n",
    "\n",
    "    ds = nc.Dataset(forcing_out, 'w')\n",
    "\n",
    "    ds.createDimension('tstep', None)\n",
    "    ds.createDimension('lat', len(rlat))\n",
    "    ds.createDimension('lon', len(rlon))\n",
    "\n",
    "    Lat = ds.createVariable('rlat', 'f4', ('lat', 'lon'))\n",
    "    Lon = ds.createVariable('rlon', 'f4', ('lat', 'lon'))\n",
    "    Lat[:]=lat.data#[100:180, 100:255]\n",
    "    Lon[:]=lon.data#[100:180, 100:255]\n",
    "\n",
    "    time = ds.createVariable('time', 'f4', ('tstep',))\n",
    "    time[:] = times_data\n",
    "\n",
    "    rlatitude = ds.createVariable('latitude','f4', ('lat'))\n",
    "    rlongitude = ds.createVariable('longitude','f4', ('lon'))\n",
    "    rlatitude[:] = rlat.data#[100:180]\n",
    "    rlongitude[:] = rlon.data#[100:255]\n",
    "    rp = ds.createVariable('rotated_pole', 'i')\n",
    "\n",
    "    psurf = ds.createVariable('PSurf', 'f4', ('tstep', 'lat', 'lon'), fill_value=Fill_value)\n",
    "    psurf[:,:,:] = PSurf.data\n",
    "    tair = ds.createVariable('Tair', 'f4', ('tstep', 'lat', 'lon'), fill_value=Fill_value)\n",
    "    tair[:,:,:] = Tair.data\n",
    "    swdown = ds.createVariable('SWdown', 'f4', ('tstep', 'lat', 'lon'), fill_value=Fill_value)\n",
    "    swdown[:,:,:] = SWdown.data\n",
    "    lwdown = ds.createVariable('LWdown', 'f4', ('tstep', 'lat', 'lon'), fill_value=Fill_value)\n",
    "    lwdown[:,:,:] = LWdown.data\n",
    "    qair = ds.createVariable('Qair', 'f4', ('tstep', 'lat', 'lon'), fill_value=Fill_value)\n",
    "    qair[:,:,:] = Qair.data\n",
    "    wind = ds.createVariable('Wind', 'f4', ('tstep', 'lat', 'lon'), fill_value=Fill_value)\n",
    "    wind[:,:,:] = Wind.data\n",
    "    snowf = ds.createVariable('Snowf', 'f4', ('tstep', 'lat', 'lon'), fill_value=Fill_value)\n",
    "    snowf[:,:,:] = Snowf\n",
    "    rainf = ds.createVariable('Rainf', 'f4', ('tstep', 'lat', 'lon'), fill_value=Fill_value)\n",
    "    rainf[:,:,:] = Rainf\n",
    "    contfrac= ds.createVariable('Contfrac', 'f4', ('lat', 'lon'), fill_value=Fill_value)\n",
    "    contfrac[:,:] = mask#[100:180, 100:255]\n",
    "\n",
    "    variables_attrs = {\n",
    "        'time':{'title': 'Time', 'long_name': 'Time axis', 'axis': 'T', 'units': f'seconds since {y}-01-01 00:00:00',\n",
    "               'calendar': '365_day'}, #noleap 'time_origin': f'{y}-JAN-01 00:00:00',\n",
    "        'latitude': {'standard_name':'latitude', 'long_name' : 'latitude', 'units' : 'degrees_north'},\n",
    "        'longitude': {'standard_name':'longitude', 'long_name' : 'longitude', 'units' : 'degrees_east'},\n",
    "        'rlat': {'standard_name':'grid_latitude', 'long_name' : 'latitude in rotated pole grid', 'units' : 'degrees', 'axis': 'Y'},\n",
    "        'rlon': {'standard_name':'grid_longitude', 'long_name' : 'longitude in rotated pole grid', 'units' : 'degrees', 'axis': 'X'},\n",
    "        'rotated_pole':{'grid_mapping_name' : 'rotated_latitude_longitude', 'grid_north_pole_latitude': 39.25, 'grid_north_pole_longitude': -162},\n",
    "        'SWdown': {'units': 'W m-2', 'long_name': 'Surface Downwelling Shortwave Radiation', 'cell_methods': 'time: mean(centre)',\n",
    "                  'grid_mapping' : 'rotated_pole', 'coordinates' : 'lat lon'},#, 'missing_value' : 9.96921e+36},\n",
    "        'LWdown': {'units': 'W m-2', 'long_name': 'Surface Downwelling Longwave Radiation', 'cell_methods': 'time: mean(centre)',\n",
    "                  'grid_mapping' : 'rotated_pole', 'coordinates' : 'lat lon'},#, 'missing_value' : 9.96921e+36},\n",
    "        'Tair':   {'units': 'K', 'long_name': 'Near-surface Air Temperature', 'cell_methods': 'time: instantaneous',\n",
    "                  'grid_mapping' : 'rotated_pole', 'coordinates' : 'lat lon'},#, 'missing_value' : 9.96921e+36},\n",
    "        'Qair':   {'units': 'kg kg-1', 'long_name': 'Near-surface specific humidity', 'cell_methods': 'time: instantaneous',\n",
    "                  'grid_mapping' : 'rotated_pole', 'coordinates' : 'lat lon'},#, 'missing_value' : 9.96921e+36},\n",
    "        'Wind':   {'units': 'm s-1', 'long_name': 'Near-surface Wind Speed', 'cell_methods': 'time: instantaneous',\n",
    "                  'grid_mapping' : 'rotated_pole', 'coordinates' : 'lat lon'},#, 'missing_value' : 9.96921e+36},\n",
    "        'PSurf':  {'units': 'Pa', 'long_name': 'Surface Air Pressure', 'cell_methods': 'time: instantaneous',\n",
    "                  'grid_mapping' : 'rotated_pole', 'coordinates' : 'lat lon'},#, 'missing_value' : 9.96921e+36},\n",
    "        'Rainf':  {'units': 'kg m-2 s-1', 'long_name': 'Rainfall Flux', 'cell_methods': 'time: mean(centre)',\n",
    "                  'grid_mapping' : 'rotated_pole', 'coordinates' : 'lat lon'},#, 'missing_value' : 9.96921e+36},\n",
    "        'Snowf':  {'units': 'kg m-2 s-1', 'long_name': 'Snowfall Flux', 'cell_methods': 'time: mean(centre)',\n",
    "                  'grid_mapping' : 'rotated_pole', 'coordinates' : 'lat lon'},#, 'missing_value' : 9.96921e+36},\n",
    "        'Contfrac': {'long_name': 'Land Area Fraction', 'grid_mapping' : 'rotated_pole', 'coordinates' : 'lat lon'}#,'missing_value' : 9.96921e+36}\n",
    "    }\n",
    "    \n",
    "    for var, attrs in variables_attrs.items():\n",
    "        for attr_name, attr_value in attrs.items():\n",
    "            ds.variables[var].setncattr(attr_name, attr_value)\n",
    "\n",
    "    ds.close() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Condizione per rilevare l'anno bisestile\\n\",\n",
    "    if (y % 4 == 0) and (y % 100 != 0 or y % 400 == 0):\n",
    "\n",
    "       # Trova l'indice temporale del 28 febbraio\\n\",\n",
    "        feb_28_index = shortwave_radiation.time.dt.strftime('%m-%d') == '02-28'\n",
    "        \n",
    "        # Duplicazione dei valori per ciascuna variabile\\n\",\n",
    "        PSurf = xr.concat([PSurf, PSurf.sel(time=feb_28_index)], dim='time')\n",
    "        Tair = xr.concat([Tair, Tair.sel(time=feb_28_index)], dim='time')\n",
    "        SWdown = xr.concat([SWdown, SWdown.sel(time=feb_28_index)], dim='time')\n",
    "        LWdown = xr.concat([LWdown, LWdown.sel(time=feb_28_index)], dim='time')\n",
    "        Qair = xr.concat([Qair, Qair.sel(time=feb_28_index)], dim='time')\n",
    "        Wind = xr.concat([Wind, Wind.sel(time=feb_28_index)], dim='time')\n",
    "        Prec = xr.concat([Prec, Prec.sel(time=feb_28_index)], dim='time')\n",
    "        \n",
    "    # Riordina i dati temporali dopo aver inserito il nuovo giorno\\n\",\n",
    "        PSurf = PSurf.sortby('time')\n",
    "        Tair = Tair.sortby('time')\n",
    "        SWdown = SWdown.sortby('time')\n",
    "        LWdown = LWdown.sortby('time')\n",
    "        Qair = Qair.sortby('time')\n",
    "        Wind = Wind.sortby('time')\n",
    "        Prec = Prec.sortby('time')\n",
    "    else:\n",
    "        pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR 1: PROJ: proj_create_from_database: Open of /net/nfs/tools/u20/Python/miniconda3_py311_23.11.0-2/envs/pangeo-meso-2024.01.22/share/proj failed\n"
     ]
    }
   ],
   "source": [
    "import netCDF4 as nc\n",
    "import cartopy.crs as ccrs\n",
    "from datetime import date, timedelta, datetime\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import dask.array as da\n",
    "import os\n",
    "import cftime\n",
    "\n",
    "############ INPUT PATH ##############\n",
    "\n",
    "rootpath_in = '/modfs/project/input4CORDEX/output/'\n",
    "CORDEX_domain = 'EUR-11'\n",
    "GCM = 'NCC-NorESM1-M'\n",
    "scenario = 'rcp45'\n",
    "RCM = 'DMI-HIRHAM5'\n",
    "em = 'r1i1p1' #ensemble_member\n",
    "ver='v3' #version\n",
    "freq='3hr' #frequency\n",
    "ver_2='latest'\n",
    "#version_3=..\n",
    "#version_4=..\n",
    "\n",
    "rootpath_out = '/modfs/project/input4CORDEX/output/'\n",
    "\n",
    "############################# TIME RANGE DEFINITION ###########\n",
    "\n",
    "first_year = 2007\n",
    "last_year = 2009\n",
    "\n",
    "years=np.arange(first_year, last_year+1, 1) #right value excluded\n",
    "\n",
    "################################# MASK CALL ######\n",
    "\n",
    "for y in years:\n",
    "\n",
    "    forcing_in = rootpath_in+CORDEX_domain+'/DMI/'+GCM+'/'+scenario+'/'+em+'/'+RCM+'/'+ver+'/'+freq+'/forcing_'+CORDEX_domain+'_'+GCM+'_'+scenario+'_'+em+'_'+RCM+'_'+ver+'_'+freq+'_'+str(y)+'365.nc'\n",
    "\n",
    "    ds = xr.open_dataset(forcing_in)\n",
    "    ds_1 = ds.isel(lat=slice(100, 180)).isel(lon=slice(100, 255))\n",
    "    #ds_1 = ds_1.rename({'latitude': 'lat'})\n",
    "    #ds_1 = ds_1.rename({'longitude': 'lon'})\n",
    "    \n",
    "    ds.close()\n",
    "\n",
    "    forcing_out = rootpath_out+CORDEX_domain+'/DMI/'+GCM+'/'+scenario+'/'+em+'/'+RCM+'/'+ver+'/'+freq+'/'+GCM+'_'+RCM+'_'+str(y)+'365.nc'\n",
    "    \n",
    "    if not os.path.isdir(os.path.dirname(forcing_out)):\n",
    "        os.makedirs(os.path.dirname(forcing_out))\n",
    "    ds_1.to_netcdf(forcing_out)\n",
    "\n",
    "    ds_1.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
